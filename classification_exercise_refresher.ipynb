{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/Md6wUj+WeGl0SeXnRmCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ed-Marcavage/PyTorch/blob/Exercises/classification_exercise_refresher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JHo4EYdh2oaB"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# Make 1000 samples\n",
        "n_samples = 1000\n",
        "\n",
        "# Create circles\n",
        "X, y = make_moons(n_samples, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X = torch.from_numpy(X).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.float)\n",
        "\n",
        "# View the first five samples\n",
        "X[:5], y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r3RVahY3PyY",
        "outputId": "88971954-187a-4135-d9a9-e48ed3a1c5c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.0087,  0.3682],\n",
              "         [ 0.9214, -0.4969],\n",
              "         [ 0.9402, -0.4982],\n",
              "         [ 0.4659, -0.3454],\n",
              "         [-0.8504,  0.5261]]),\n",
              " tensor([1., 1., 1., 1., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.2, # 20% test, 80% train\n",
        "                                                    random_state=42) # make the random split reproducible\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "id": "wUt6lsYr3P03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eae5738-a909-4b11-cfaf-b2d9414ab717"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 200, 800, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard PyTorch imports\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Make device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "DLSzoCoZ3P3H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24a179cb-a83b-4ff3-bf0f-1ce87dee55c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_0 = nn.Sequential(\n",
        "#     nn.Linear(in_features=2, out_features=5),\n",
        "#     nn.Linear(in_features=5, out_features=1)\n",
        "# ).to(device)\n",
        "\n",
        "# model_0\n",
        "\n",
        "class warmUpModelv0(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer_one = nn.Linear(in_features=2, out_features=5) # takes in 2 features (X), UPSCALES to 5 features\n",
        "    self.layer_two = nn.Linear(in_features=5, out_features=1) # takes in 5 features, produces 1 feature (y)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layer_two(self.layer_one(x))\n",
        "\n",
        "# 4. Create an instance of the model and send it to target device\n",
        "model_0 = warmUpModelv0().to(device)\n",
        "model_0"
      ],
      "metadata": {
        "id": "Ik7Ackz03P5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1b1501-2288-44a6-ecc8-dfe5fbb86d76"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "warmUpModelv0(\n",
              "  (layer_one): Linear(in_features=2, out_features=5, bias=True)\n",
              "  (layer_two): Linear(in_features=5, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWSFupxcjCZJ",
        "outputId": "009503c9-aa6d-4b34-ea5a-a2cab1fc78b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer_one.weight',\n",
              "              tensor([[ 0.1881,  0.5282],\n",
              "                      [ 0.0734,  0.1517],\n",
              "                      [-0.5631,  0.6648],\n",
              "                      [-0.6878, -0.6102],\n",
              "                      [-0.2676, -0.0422]])),\n",
              "             ('layer_one.bias',\n",
              "              tensor([ 0.3230,  0.0487, -0.5743, -0.5761,  0.1835])),\n",
              "             ('layer_two.weight',\n",
              "              tensor([[-0.2665,  0.0442, -0.4323, -0.3174,  0.1822]])),\n",
              "             ('layer_two.bias', tensor([-0.1603]))])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device, next(model_0.parameters()).device"
      ],
      "metadata": {
        "id": "FSaFuyqh3P7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6690508-09d3-437f-f28d-c4dcd1a3b060"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('cpu', device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  untrained_preds = model_0(X_test.to(device))\n",
        "untrained_preds = model_0(X_test.to(device))\n",
        "print(f\"Length of predictions: {len(untrained_preds)}, Shape: {untrained_preds.shape}\")\n",
        "print(f\"Length of test samples: {len(y_test)}, Shape: {y_test.shape}\")\n",
        "print(f\"\\nFirst 10 predictions:\\n{untrained_preds[:10]}\")\n",
        "print(f\"\\nFirst 10 test labels:\\n{y_test[:10]}\")"
      ],
      "metadata": {
        "id": "EiqQYH3w3P9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d836fb0c-ebc3-4b53-90bd-bc637b511143"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of predictions: 200, Shape: torch.Size([200, 1])\n",
            "Length of test samples: 200, Shape: torch.Size([200])\n",
            "\n",
            "First 10 predictions:\n",
            "tensor([[0.4887],\n",
            "        [0.3013],\n",
            "        [0.7776],\n",
            "        [0.2387],\n",
            "        [0.9028],\n",
            "        [0.8924],\n",
            "        [0.4998],\n",
            "        [0.5626],\n",
            "        [0.7535],\n",
            "        [0.3254]], grad_fn=<SliceBackward0>)\n",
            "\n",
            "First 10 test labels:\n",
            "tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "T7FxzdgoiaOw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train model\n",
        "- Forward Pass\n",
        "- Calc the loss\n",
        "- Zero gradients\n",
        "- Perform backpropagation on the loss\n",
        "- Ser the optimizer (gradient descent)\n",
        "\n",
        "\n",
        "###Going from raw model outputs to predicted labels (logits -> prediction probabilities -> prediction labels)\n"
      ],
      "metadata": {
        "id": "UBZwXiUAinm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  y_logits = model_0(X_test.to(device))[:5]\n",
        "y_logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2so-0CMiibl",
        "outputId": "fa4b1100-32e9-4eaa-d168-71a759b162ff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4887],\n",
              "        [0.3013],\n",
              "        [0.7776],\n",
              "        [0.2387],\n",
              "        [0.9028]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use sigmoid on model logits\n",
        "y_pred_probs = torch.sigmoid(y_logits)\n",
        "y_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FklDamc2iu49",
        "outputId": "74287e5e-6f7c-4511-a6ef-ccf368373f00"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6198],\n",
              "        [0.5748],\n",
              "        [0.6852],\n",
              "        [0.5594],\n",
              "        [0.7115]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the predicted labels (round the prediction probabilities)\n",
        "y_preds = torch.round(y_pred_probs)\n",
        "\n",
        "# In full\n",
        "y_pred_labels = torch.round(torch.sigmoid(model_0(X_test.to(device))[:5]))\n",
        "\n",
        "# Check for equality\n",
        "print(torch.eq(y_preds.squeeze(), y_pred_labels.squeeze()))\n",
        "\n",
        "# Get rid of extra dimension\n",
        "y_preds.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B9De9ivjWld",
        "outputId": "97f19e62-8776-40a2-a056-06ac783dcc8e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),lr=0.1)"
      ],
      "metadata": {
        "id": "jAaRsNfb3QAV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 100\n",
        "\n",
        "# Put data to target device\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "\n",
        "# Build training and evaluation loop\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    ### Set Training Mode\n",
        "    model_0.train()\n",
        "\n",
        "    # 1. Forward pass (model outputs raw logits)\n",
        "    y_logits = model_0(X_train).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device\n",
        "    y_pred = torch.round(torch.sigmoid(y_logits)) # turn logits -> pred probs -> pred labls\n",
        "\n",
        "    # 2. Calculate loss/accuracy\n",
        "    # loss = loss_fn(torch.sigmoid(y_logits), # Using nn.BCELoss you need torch.sigmoid()\n",
        "    #                y_train)\n",
        "    loss = loss_fn(y_logits, # Using nn.BCEWithLogitsLoss works with raw logits\n",
        "                   y_train)\n",
        "\n",
        "    acc = accuracy_fn(y_true=y_train,\n",
        "                      y_pred=y_pred)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        # 1. Forward pass\n",
        "        test_logits = model_0(X_test).squeeze()\n",
        "        test_pred = torch.round(torch.sigmoid(test_logits)) # sigmoid - creates preds probs\n",
        "        # 2. Caculate loss/accuracy\n",
        "        test_loss = loss_fn(test_logits,\n",
        "                            y_test)\n",
        "        test_acc = accuracy_fn(y_true=y_test,\n",
        "                               y_pred=test_pred)\n",
        "\n",
        "    # Print out what's happening every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aECyl7kjbNX",
        "outputId": "21e03253-da8b-4d87-d61e-dd69324de90a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.58596, Accuracy: 76.62% | Test loss: 0.59313, Test acc: 73.50%\n",
            "Epoch: 10 | Loss: 0.51987, Accuracy: 81.75% | Test loss: 0.53038, Test acc: 80.50%\n",
            "Epoch: 20 | Loss: 0.45970, Accuracy: 82.12% | Test loss: 0.47383, Test acc: 83.00%\n",
            "Epoch: 30 | Loss: 0.40944, Accuracy: 82.75% | Test loss: 0.42667, Test acc: 84.00%\n",
            "Epoch: 40 | Loss: 0.37123, Accuracy: 83.38% | Test loss: 0.39039, Test acc: 84.50%\n",
            "Epoch: 50 | Loss: 0.34365, Accuracy: 83.62% | Test loss: 0.36356, Test acc: 85.00%\n",
            "Epoch: 60 | Loss: 0.32392, Accuracy: 84.25% | Test loss: 0.34372, Test acc: 84.50%\n",
            "Epoch: 70 | Loss: 0.30952, Accuracy: 84.50% | Test loss: 0.32868, Test acc: 85.00%\n",
            "Epoch: 80 | Loss: 0.29866, Accuracy: 84.88% | Test loss: 0.31689, Test acc: 85.50%\n",
            "Epoch: 90 | Loss: 0.29014, Accuracy: 85.00% | Test loss: 0.30733, Test acc: 87.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7qgF-SJ-jeDa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}